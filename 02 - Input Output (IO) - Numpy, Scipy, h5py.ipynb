{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input/Output\n",
    "\n",
    "Often, it is important to import information from a variety of sources and output the result. A few ways of creating and saving files are demonstrated.\n",
    "\n",
    "By the end of this file you should have seen simple examples of:\n",
    "1. Printing string output to the screen\n",
    "2. Reading and writing string output to/from text files\n",
    "3. Reading and writing string output to/from csv files\n",
    "4. Reading and writing string output to/from binary files\n",
    "5. Reading and writing string output to/from matlab files\n",
    "\n",
    "Further reading:  \n",
    "http://docs.h5py.org/en/latest/index.html  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\BACKUP_AWAYFROMONEDRIVE\\Blake Files\\Learning\\IntroScientificPythonWithJupyter\\datafiles\n",
      "01-data_write.hdf5\n",
      "01-simpledata.csv\n",
      "01-simpledata_write.bin\n",
      "01-simpledata_write.csv\n",
      "01-simplemat.mat\n",
      "01-simplemat_write.mat\n",
      "01-simpletext.txt\n",
      "01-simpletext_write.txt\n",
      "pandas_df1.csv\n",
      "pandas_df1.h5\n",
      "presentation.mplstyle\n"
     ]
    }
   ],
   "source": [
    "# Python Imports:\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "%cd datafiles\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From standard input/keyboard:\n",
    "The import of simple text files can be performed directly in python via: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n"
     ]
    }
   ],
   "source": [
    "kb_contents = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit.'\n",
    "print(kb_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text (ascii) files:\n",
    "The import of simple text files can be performed directly in python by creating a file object and operating on that object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam leo purus, interdum sed interdum quis, tincidunt ac nibh. \n",
      "\n",
      "\n",
      "\n",
      "Maecenas a purus massa. Nunc a augue augue. Donec in felis commodo lectus convallis elementum sed vitae ipsum.\n"
     ]
    }
   ],
   "source": [
    "# Read line by line:\n",
    "file_obj = open('01-simpletext.txt','r')\n",
    "for line in file_obj:\n",
    "    print(line)\n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam leo purus, interdum sed interdum quis, tincidunt ac nibh. \n",
      "\n",
      "Maecenas a purus massa. Nunc a augue augue. Donec in felis commodo lectus convallis elementum sed vitae ipsum.\n"
     ]
    }
   ],
   "source": [
    "# Use the read method:\n",
    "file_obj = open('01-simpletext.txt','r')\n",
    "file_contents = file_obj.read()\n",
    "file_obj.close()\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam leo purus, interdum sed interdum quis, tincidunt ac nibh. \n",
      "\n",
      "Maecenas a purus massa. Nunc a augue augue. Donec in felis commodo lectus convallis elementum sed vitae ipsum.\n"
     ]
    }
   ],
   "source": [
    "# Python 'with' statement automatically takes care of the close for us:\n",
    "with open('01-simpletext.txt','r') as file_obj:\n",
    "    print(file_obj.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam leo purus, interdum sed interdum quis, tincidunt ac nibh. \n",
      "\n",
      "Maecenas a purus massa. Nunc a augue augue. Donec in felis commodo lectus convallis elementum sed vitae ipsum.\n"
     ]
    }
   ],
   "source": [
    "# Write to ascii files:\n",
    "file_obj = open('01-simpletext_write.txt','w')\n",
    "file_obj.write(file_contents)\n",
    "file_obj.close()\n",
    "\n",
    "# Or, alternatively:\n",
    "with open('01-simpletext_write.txt','w') as file_obj:\n",
    "    file_obj.write(file_contents)\n",
    "\n",
    "# Check that our written output is good:\n",
    "with open('01-simpletext_write.txt','r') as file_obj:\n",
    "    print(file_obj.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comma Separated Values (.csv files):\n",
    "Here, we import data separated by a particular delimiter, as in tsv or csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '0.012', '2', '0.024\\n2', '0.014', '4', '0.056\\n3', '0.016', '8', '0.128\\n4', '0.018', '16', '0.288\\n5', '0.020', '32', '0.640\\n6', '0.022', '64', '1.408\\n7', '0.024', '128', '3.072\\n8', '0.026', '256', '6.656\\n9', '0.028', '512', '14.336\\n10', '0.030', '1024', '30.720']\n"
     ]
    }
   ],
   "source": [
    "# Creating a python list:\n",
    "with open('01-simpledata.csv','r') as file_obj:\n",
    "    file_contents = file_obj.read().split(',')\n",
    "    \n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   1.20000000e-02   2.00000000e+00   2.40000000e-02]\n",
      " [  2.00000000e+00   1.40000000e-02   4.00000000e+00   5.60000000e-02]\n",
      " [  3.00000000e+00   1.60000000e-02   8.00000000e+00   1.28000000e-01]\n",
      " [  4.00000000e+00   1.80000000e-02   1.60000000e+01   2.88000000e-01]\n",
      " [  5.00000000e+00   2.00000000e-02   3.20000000e+01   6.40000000e-01]\n",
      " [  6.00000000e+00   2.20000000e-02   6.40000000e+01   1.40800000e+00]\n",
      " [  7.00000000e+00   2.40000000e-02   1.28000000e+02   3.07200000e+00]\n",
      " [  8.00000000e+00   2.60000000e-02   2.56000000e+02   6.65600000e+00]\n",
      " [  9.00000000e+00   2.80000000e-02   5.12000000e+02   1.43360000e+01]\n",
      " [  1.00000000e+01   3.00000000e-02   1.02400000e+03   3.07200000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Use numpy to read an array from a file\n",
    "file_contents = np.loadtxt(open('01-simpledata.csv'), delimiter=\",\")\n",
    "file_contents = file_contents.astype('float')\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.00000000e+00   2.40000000e-02   4.00000000e+00   4.80000000e-02]\n",
      " [  4.00000000e+00   2.80000000e-02   8.00000000e+00   1.12000000e-01]\n",
      " [  6.00000000e+00   3.20000000e-02   1.60000000e+01   2.56000000e-01]\n",
      " [  8.00000000e+00   3.60000000e-02   3.20000000e+01   5.76000000e-01]\n",
      " [  1.00000000e+01   4.00000000e-02   6.40000000e+01   1.28000000e+00]\n",
      " [  1.20000000e+01   4.40000000e-02   1.28000000e+02   2.81600000e+00]\n",
      " [  1.40000000e+01   4.80000000e-02   2.56000000e+02   6.14400000e+00]\n",
      " [  1.60000000e+01   5.20000000e-02   5.12000000e+02   1.33120000e+01]\n",
      " [  1.80000000e+01   5.60000000e-02   1.02400000e+03   2.86720000e+01]\n",
      " [  2.00000000e+01   6.00000000e-02   2.04800000e+03   6.14400000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Save output of numpy array to csv file\n",
    "file_contents_write = file_contents*2 #Double to differentiate read vs write data\n",
    "\n",
    "np.savetxt('01-simpledata_write.csv',file_contents_write, '%0.3f', delimiter=\",\") \n",
    "# %0.3f specifies scientific notation with 3 decimal places\n",
    "file_contents = np.loadtxt(open('01-simpledata_write.csv'), delimiter=\",\")\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Files:\n",
    "Binary files store the same information as text or csv, but do so directly in bytes, rather than using ascii to encode. They have the advantage of being faster to read and smaller in size, but are not readily readable by a typical text editor (notepad, vim, sublime, etc).\n",
    "\n",
    "Note: be careful to avoid `numpy.fromfile` and `numpy.tofile` as they are not platform independent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.00000000e+00   2.40000000e-02   4.00000000e+00   4.80000000e-02]\n",
      " [  4.00000000e+00   2.80000000e-02   8.00000000e+00   1.12000000e-01]\n",
      " [  6.00000000e+00   3.20000000e-02   1.60000000e+01   2.56000000e-01]\n",
      " [  8.00000000e+00   3.60000000e-02   3.20000000e+01   5.76000000e-01]\n",
      " [  1.00000000e+01   4.00000000e-02   6.40000000e+01   1.28000000e+00]\n",
      " [  1.20000000e+01   4.40000000e-02   1.28000000e+02   2.81600000e+00]\n",
      " [  1.40000000e+01   4.80000000e-02   2.56000000e+02   6.14400000e+00]\n",
      " [  1.60000000e+01   5.20000000e-02   5.12000000e+02   1.33120000e+01]\n",
      " [  1.80000000e+01   5.60000000e-02   1.02400000e+03   2.86720000e+01]\n",
      " [  2.00000000e+01   6.00000000e-02   2.04800000e+03   6.14400000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Read in the csv from the previous step:\n",
    "file_contents = np.loadtxt(open('01-simpledata_write.csv'), delimiter=\",\")\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.00000000e+00   4.80000000e-02   8.00000000e+00   9.60000000e-02]\n",
      " [  8.00000000e+00   5.60000000e-02   1.60000000e+01   2.24000000e-01]\n",
      " [  1.20000000e+01   6.40000000e-02   3.20000000e+01   5.12000000e-01]\n",
      " [  1.60000000e+01   7.20000000e-02   6.40000000e+01   1.15200000e+00]\n",
      " [  2.00000000e+01   8.00000000e-02   1.28000000e+02   2.56000000e+00]\n",
      " [  2.40000000e+01   8.80000000e-02   2.56000000e+02   5.63200000e+00]\n",
      " [  2.80000000e+01   9.60000000e-02   5.12000000e+02   1.22880000e+01]\n",
      " [  3.20000000e+01   1.04000000e-01   1.02400000e+03   2.66240000e+01]\n",
      " [  3.60000000e+01   1.12000000e-01   2.04800000e+03   5.73440000e+01]\n",
      " [  4.00000000e+01   1.20000000e-01   4.09600000e+03   1.22880000e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Save as a binary file:\n",
    "np.savetxt('01-simpledata_write.bin', file_contents_write*2) # Note the lack of demiliter\n",
    "file_contents = np.loadtxt('01-simpledata_write.bin')\n",
    "\n",
    "# The following is not recommended, as it is platform dependent:\n",
    "#np.ndarray.tofile(file_contents_write, '01-simpledata_write.bin')\n",
    "#file_contents = np.fromfile('01-simpledata_write.bin')\n",
    "\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matlab (.mat) files:\n",
    "Generating matlab variables via:\n",
    "\n",
    "``testvar = magic(9)``\n",
    "\n",
    "``save('01-simplemat.mat','testvar')``\n",
    "\n",
    "These can then be loaded via scipy.io (imported as sio here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47 58 69 80  1 12 23 34 45]\n",
      " [57 68 79  9 11 22 33 44 46]\n",
      " [67 78  8 10 21 32 43 54 56]\n",
      " [77  7 18 20 31 42 53 55 66]\n",
      " [ 6 17 19 30 41 52 63 65 76]\n",
      " [16 27 29 40 51 62 64 75  5]\n",
      " [26 28 39 50 61 72 74  4 15]\n",
      " [36 38 49 60 71 73  3 14 25]\n",
      " [37 48 59 70 81  2 13 24 35]]\n"
     ]
    }
   ],
   "source": [
    "# Use scipy to read in .mat files:\n",
    "mat_contents= sio.loadmat('01-simplemat.mat')\n",
    "\n",
    "testvar = mat_contents['testvar']\n",
    "print(testvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 94 116 138 160   2  24  46  68  90]\n",
      " [114 136 158  18  22  44  66  88  92]\n",
      " [134 156  16  20  42  64  86 108 112]\n",
      " [154  14  36  40  62  84 106 110 132]\n",
      " [ 12  34  38  60  82 104 126 130 152]\n",
      " [ 32  54  58  80 102 124 128 150  10]\n",
      " [ 52  56  78 100 122 144 148   8  30]\n",
      " [ 72  76  98 120 142 146   6  28  50]\n",
      " [ 74  96 118 140 162   4  26  48  70]]\n"
     ]
    }
   ],
   "source": [
    "# Use scipy to write .mat files:\n",
    "testvar_write = testvar*2 # Double to make read data different from write data\n",
    "\n",
    "sio.savemat('01-simplemat_write.mat' ,{'testvar_write':testvar_write})\n",
    "\n",
    "mat_contents = sio.loadmat('01-simplemat_write.mat')\n",
    "testvar = mat_contents['testvar_write']\n",
    "print(testvar_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 files\n",
    "\n",
    "HDF5 or Hierarchical Data Format provides a file format that has a much greater amount of flexibility at the cost of a bit more complexity. HDF5 is ideal when there would otherwise have been many small files. There are two main objects:\n",
    "- Groups: folder-like containers that work like Python dictionaries\n",
    "- Datasets: NumPy-like arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv data:\n",
    "data_csv = np.loadtxt(open('01-simpledata_write.csv'), delimiter=\",\")\n",
    "\n",
    "# Load mat data:\n",
    "data_mat = sio.loadmat('01-simplemat_write.mat')['testvar_write']\n",
    "\n",
    "# Load text data:\n",
    "with open('01-simpletext.txt','r') as file_obj:\n",
    "    data_txt = file_obj.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a h5py file object:\n",
    "with h5py.File(\"01-data_write.hdf5\", \"w\") as file_obj:   \n",
    "    # Use file_obj to create data sets\n",
    "    \n",
    "    # Create a dataset object and assign the values from data:\n",
    "    dataset1 = file_obj.create_dataset(\"data\", data = data_csv)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the data has been written to the file by opening it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data\n",
      "[[  2.00000000e+00   2.40000000e-02   4.00000000e+00   4.80000000e-02]\n",
      " [  4.00000000e+00   2.80000000e-02   8.00000000e+00   1.12000000e-01]\n",
      " [  6.00000000e+00   3.20000000e-02   1.60000000e+01   2.56000000e-01]\n",
      " [  8.00000000e+00   3.60000000e-02   3.20000000e+01   5.76000000e-01]\n",
      " [  1.00000000e+01   4.00000000e-02   6.40000000e+01   1.28000000e+00]\n",
      " [  1.20000000e+01   4.40000000e-02   1.28000000e+02   2.81600000e+00]\n",
      " [  1.40000000e+01   4.80000000e-02   2.56000000e+02   6.14400000e+00]\n",
      " [  1.60000000e+01   5.20000000e-02   5.12000000e+02   1.33120000e+01]\n",
      " [  1.80000000e+01   5.60000000e-02   1.02400000e+03   2.86720000e+01]\n",
      " [  2.00000000e+01   6.00000000e-02   2.04800000e+03   6.14400000e+01]]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"01-data_write.hdf5\", 'r') as file_obj:\n",
    "    print(file_obj[\"data\"].name)\n",
    "    print(file_obj[\"data\"].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Hierarchical\" part of the HDF5 file format provides groups, which act like Python dictionaries or 'folders' for the various Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the same h5py file object:\n",
    "with h5py.File(\"01-data_write.hdf5\", \"w\") as file_obj:\n",
    "\n",
    "    # Create a group object, and create datasets underneath it:\n",
    "    grp_nums = file_obj.create_group(\"Numbers\")\n",
    "    dataset_csv = grp_nums.create_dataset(\"CSV\", data=data_csv)\n",
    "    dataset_mat = grp_nums.create_dataset(\"MAT\", data=data_mat)\n",
    "\n",
    "    # Create a second group object, and create datasets underneath it:\n",
    "    grp_txt = file_obj.create_group(\"Text\")\n",
    "    txt_hf5 = np.asarray(data_txt, dtype=\"S\") # Convert to NumPy S dtype:\n",
    "    dataset_txt = grp_txt.create_dataset(\"lorem\", data=txt_hf5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving this data, check the file structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers\n",
      "<HDF5 group \"/Numbers\" (2 members)>\n",
      "Numbers/CSV\n",
      "<HDF5 dataset \"CSV\": shape (10, 4), type \"<f8\">\n",
      "Numbers/MAT\n",
      "<HDF5 dataset \"MAT\": shape (9, 9), type \"|u1\">\n",
      "Text\n",
      "<HDF5 group \"/Text\" (1 members)>\n",
      "Text/lorem\n",
      "<HDF5 dataset \"lorem\": shape (), type \"|S231\">\n"
     ]
    }
   ],
   "source": [
    "def print_attrs(name, obj): # Function that prints the name and object\n",
    "    print(name)\n",
    "    print(obj)\n",
    "        \n",
    "with h5py.File(\"01-data_write.hdf5\", 'r') as file_obj:\n",
    "    file_obj.visititems(print_attrs) # Use .visititems to get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Numbers/CSV\n",
      "[[  2.00000000e+00   2.40000000e-02   4.00000000e+00   4.80000000e-02]\n",
      " [  4.00000000e+00   2.80000000e-02   8.00000000e+00   1.12000000e-01]\n",
      " [  6.00000000e+00   3.20000000e-02   1.60000000e+01   2.56000000e-01]\n",
      " [  8.00000000e+00   3.60000000e-02   3.20000000e+01   5.76000000e-01]\n",
      " [  1.00000000e+01   4.00000000e-02   6.40000000e+01   1.28000000e+00]\n",
      " [  1.20000000e+01   4.40000000e-02   1.28000000e+02   2.81600000e+00]\n",
      " [  1.40000000e+01   4.80000000e-02   2.56000000e+02   6.14400000e+00]\n",
      " [  1.60000000e+01   5.20000000e-02   5.12000000e+02   1.33120000e+01]\n",
      " [  1.80000000e+01   5.60000000e-02   1.02400000e+03   2.86720000e+01]\n",
      " [  2.00000000e+01   6.00000000e-02   2.04800000e+03   6.14400000e+01]]\n",
      "/Numbers/MAT\n",
      "[[ 94 116 138 160   2  24  46  68  90]\n",
      " [114 136 158  18  22  44  66  88  92]\n",
      " [134 156  16  20  42  64  86 108 112]\n",
      " [154  14  36  40  62  84 106 110 132]\n",
      " [ 12  34  38  60  82 104 126 130 152]\n",
      " [ 32  54  58  80 102 124 128 150  10]\n",
      " [ 52  56  78 100 122 144 148   8  30]\n",
      " [ 72  76  98 120 142 146   6  28  50]\n",
      " [ 74  96 118 140 162   4  26  48  70]]\n",
      "/Text/lorem\n",
      "b'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam leo purus, interdum sed interdum quis, tincidunt ac nibh. \\n\\nMaecenas a purus massa. Nunc a augue augue. Donec in felis commodo lectus convallis elementum sed vitae ipsum.'\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"01-data_write.hdf5\", 'r') as file_obj:\n",
    "    print(file_obj[\"/Numbers/CSV\"].name)\n",
    "    print(file_obj[\"/Numbers/CSV\"].value)\n",
    "    \n",
    "    print(file_obj[\"/Numbers/MAT\"].name)\n",
    "    print(file_obj[\"/Numbers/MAT\"].value)\n",
    "    \n",
    "    print(file_obj[\"/Text/lorem\"].name)\n",
    "    print(file_obj[\"/Text/lorem\"].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For coinvenience, it's possible to print all of the information using `.visititems`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers\n",
      "<HDF5 group \"/Numbers\" (2 members)>\n",
      "Numbers/CSV\n",
      "[[  2.00000000e+00   2.40000000e-02   4.00000000e+00   4.80000000e-02]\n",
      " [  4.00000000e+00   2.80000000e-02   8.00000000e+00   1.12000000e-01]\n",
      " [  6.00000000e+00   3.20000000e-02   1.60000000e+01   2.56000000e-01]\n",
      " [  8.00000000e+00   3.60000000e-02   3.20000000e+01   5.76000000e-01]\n",
      " [  1.00000000e+01   4.00000000e-02   6.40000000e+01   1.28000000e+00]\n",
      " [  1.20000000e+01   4.40000000e-02   1.28000000e+02   2.81600000e+00]\n",
      " [  1.40000000e+01   4.80000000e-02   2.56000000e+02   6.14400000e+00]\n",
      " [  1.60000000e+01   5.20000000e-02   5.12000000e+02   1.33120000e+01]\n",
      " [  1.80000000e+01   5.60000000e-02   1.02400000e+03   2.86720000e+01]\n",
      " [  2.00000000e+01   6.00000000e-02   2.04800000e+03   6.14400000e+01]]\n",
      "Numbers/MAT\n",
      "[[ 94 116 138 160   2  24  46  68  90]\n",
      " [114 136 158  18  22  44  66  88  92]\n",
      " [134 156  16  20  42  64  86 108 112]\n",
      " [154  14  36  40  62  84 106 110 132]\n",
      " [ 12  34  38  60  82 104 126 130 152]\n",
      " [ 32  54  58  80 102 124 128 150  10]\n",
      " [ 52  56  78 100 122 144 148   8  30]\n",
      " [ 72  76  98 120 142 146   6  28  50]\n",
      " [ 74  96 118 140 162   4  26  48  70]]\n",
      "Text\n",
      "<HDF5 group \"/Text\" (1 members)>\n",
      "Text/lorem\n",
      "b'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam leo purus, interdum sed interdum quis, tincidunt ac nibh. \\n\\nMaecenas a purus massa. Nunc a augue augue. Donec in felis commodo lectus convallis elementum sed vitae ipsum.'\n"
     ]
    }
   ],
   "source": [
    "def print_attrs(name, obj):\n",
    "    print(name)\n",
    "    if isinstance(obj, h5py.Group):\n",
    "        print(obj)\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        print(obj.value)\n",
    "        \n",
    "with h5py.File(\"01-data_write.hdf5\", 'r') as file_obj:\n",
    "    file_obj.visititems(print_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h5py also allows storing of metadata relating to data - check the h5py documentation for more info: http://docs.h5py.org/en/latest/index.html  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
